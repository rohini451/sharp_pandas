{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4628fdea-9222-4a97-ba4e-3f470b4cb7dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0xff7b47cb4890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pandas vs PySpark Test\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b265ed67-86c7-4c2b-910f-380ba283b415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Version:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fa2a810-2a83-47c1-8add-7f1c7e665bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas load time: 0.017216205596923828 seconds\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.363911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.448929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.669486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.296567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     value\n",
       "0   0  0.363911\n",
       "1   1  0.996588\n",
       "2   2  0.448929\n",
       "3   3  0.669486\n",
       "4   4  0.296567"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a Pandas DataFrame with 1 million rows\n",
    "pdf = pd.DataFrame({\n",
    "    \"id\": np.arange(1_000_000),\n",
    "    \"value\": np.random.rand(1_000_000)\n",
    "})\n",
    "\n",
    "pandas_time = time.time() - start_time\n",
    "\n",
    "print(\"Pandas load time:\", pandas_time, \"seconds\")\n",
    "pdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61f7ccae-205b-442f-9d18-ec2f8fa3cf09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark load time: 0.00022792816162109375 seconds\n+---+--------------------+\n| id|               value|\n+---+--------------------+\n|  0|  0.5561970257242097|\n|  1|  0.9540500681977229|\n|  2|  0.9738212926507727|\n|  3|0.039388019218153825|\n|  4| 0.37993414348299015|\n+---+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a Spark DataFrame with 1 million rows\n",
    "sdf = spark.range(1_000_000).withColumn(\"value\", rand())\n",
    "\n",
    "spark_time = time.time() - start_time\n",
    "\n",
    "print(\"PySpark load time:\", spark_time, \"seconds\")\n",
    "sdf.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b81f2f5-6eca-4f04-a4af-65fbfef71d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n===== Performance Comparison =====\nPandas load time:   0.0172 seconds\nPySpark load time:  0.0002 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Performance Comparison =====\")\n",
    "print(f\"Pandas load time:   {pandas_time:.4f} seconds\")\n",
    "print(f\"PySpark load time:  {spark_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe7c5996-56bd-4c84-86b7-1e34f2cff956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SampleCSVRead\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beac8926-3a01-4f94-9b65-60539fbfce73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/databricks-datasets/samples/population-vs-price/data_geo.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2869cd-b2cc-4829-9d3b-8fccc22ddc78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------+----------+------------------------+-----------------------+\n|2014 rank|         City|  State|State Code|2014 Population estimate|2015 median sales price|\n+---------+-------------+-------+----------+------------------------+-----------------------+\n|      101|   Birmingham|Alabama|        AL|                  212247|                  162.9|\n|      125|   Huntsville|Alabama|        AL|                  188226|                  157.7|\n|      122|       Mobile|Alabama|        AL|                  194675|                  122.5|\n|      114|   Montgomery|Alabama|        AL|                  200481|                  129.0|\n|       64|Anchorage[19]| Alaska|        AK|                  301010|                   NULL|\n+---------+-------------+-------+----------+------------------------+-----------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9660d872-d050-40c0-a9bd-9f0d419f4583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- 2014 rank: integer (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n |-- State Code: string (nullable = true)\n |-- 2014 Population estimate: integer (nullable = true)\n |-- 2015 median sales price: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65be5d50-4cc9-4444-a985-39ee8e61d4f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "basic sql function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81995638-1169-4273-a3a9-209059a0d64f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6160aa2e-e58d-423f-876b-627911c660b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------+\n|         City|2014 Population estimate|\n+-------------+------------------------+\n|   Birmingham|                  212247|\n|   Huntsville|                  188226|\n|       Mobile|                  194675|\n|   Montgomery|                  200481|\n|Anchorage[19]|                  301010|\n+-------------+------------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"City\", \"2014 Population estimate\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef9d84f-780c-4ac0-a945-568fa2a8b99f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------+----------+------------------------+-----------------------+\n|2014 rank|           City|       State|State Code|2014 Population estimate|2015 median sales price|\n+---------+---------------+------------+----------+------------------------+-----------------------+\n|        6|        Phoenix|     Arizona|        AZ|                 1537058|                  206.1|\n|        2|    Los Angeles|  California|        CA|                 3928864|                  434.7|\n|        8|      San Diego|  California|        CA|                 1381069|                  510.3|\n|       10|       San Jose|  California|        CA|                 1015785|                  900.0|\n|        3|        Chicago|    Illinois|        IL|                 2722389|                  192.5|\n|        1|    New York[6]|    New York|        NY|                 8491079|                  388.6|\n|        5|Philadelphia[8]|Pennsylvania|        PA|                 1560297|                  204.9|\n|        9|         Dallas|       Texas|        TX|                 1281047|                  192.5|\n|        4|     Houston[7]|       Texas|        TX|                 2239558|                  200.3|\n|        7|    San Antonio|       Texas|        TX|                 1436697|                  184.7|\n+---------+---------------+------------+----------+------------------------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"2014 Population estimate\"] > 1000000).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c74ad0e5-a6da-4d08-a5b1-de44bbcb580f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------+----------+------------------------+-----------------------+\n|2014 rank|           City|       State|State Code|2014 Population estimate|2015 median sales price|\n+---------+---------------+------------+----------+------------------------+-----------------------+\n|        1|    New York[6]|    New York|        NY|                 8491079|                  388.6|\n|        2|    Los Angeles|  California|        CA|                 3928864|                  434.7|\n|        3|        Chicago|    Illinois|        IL|                 2722389|                  192.5|\n|        4|     Houston[7]|       Texas|        TX|                 2239558|                  200.3|\n|        5|Philadelphia[8]|Pennsylvania|        PA|                 1560297|                  204.9|\n+---------+---------------+------------+----------+------------------------+-----------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"2014 Population estimate\"].desc()).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27a0f607-d054-4d06-b5e9-45db6f5c6916",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4be39a8-d4c4-4b60-9e6d-660400f8e709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+----------+------------------------+-----------------------+\n|2014 rank|City|State|State Code|2014 Population estimate|2015 median sales price|\n+---------+----+-----+----------+------------------------+-----------------------+\n|        0|   0|    0|         0|                       1|                    185|\n+---------+----+-----+----------+------------------------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81de09c-f733-4637-9bf5-481928b13f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+----------+------------------------+-----------------------+\n|2014 rank|      City|  State|State Code|2014 Population estimate|2015 median sales price|\n+---------+----------+-------+----------+------------------------+-----------------------+\n|      101|Birmingham|Alabama|        AL|                  212247|                  162.9|\n|      125|Huntsville|Alabama|        AL|                  188226|                  157.7|\n|      122|    Mobile|Alabama|        AL|                  194675|                  122.5|\n|      114|Montgomery|Alabama|        AL|                  200481|                  129.0|\n|        6|   Phoenix|Arizona|        AZ|                 1537058|                  206.1|\n+---------+----------+-------+----------+------------------------+-----------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.dropna()\n",
    "df_clean.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf3ba31-f9e6-41b2-aacf-efc10421182f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+------------------------+-------------------+\n|         City|  State|2014 Population estimate|Average_House_Price|\n+-------------+-------+------------------------+-------------------+\n|   Birmingham|Alabama|                  212247|              162.9|\n|   Huntsville|Alabama|                  188226|              157.7|\n|       Mobile|Alabama|                  194675|              122.5|\n|   Montgomery|Alabama|                  200481|              129.0|\n|Anchorage[19]| Alaska|                  301010|               NULL|\n+-------------+-------+------------------------+-------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_selected = df.select(\"City\", \"State\", \"2014 Population estimate\", \"2015 median sales price\")\n",
    "df_selected.withColumnRenamed(\"2015 median sales price\", \"Average_House_Price\").show(5)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark basics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}